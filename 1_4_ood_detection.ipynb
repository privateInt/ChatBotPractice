{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "## OOD classification 테스크를 위한 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "from src.dataset import Preprocessing\n",
    "from src.model import EpochLogger, MakeEmbed, save\n",
    "\n",
    "class MakeDataset:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.intent_ood_label_dir = \"./data/dataset/intent_label_with_ood.json\"\n",
    "        self.intent_data_dir = \"./data/dataset/intent_data.csv\"\n",
    "        self.ood_data_dir = \"./data/dataset/ood_data.csv\"\n",
    "        \n",
    "        self.intent_ood_label = self.load_intent_ood_label()\n",
    "        self.prep = Preprocessing()\n",
    "    \n",
    "    def load_intent_ood_label(self):\n",
    "        f = open(self.intent_ood_label_dir, encoding=\"UTF-8\")\n",
    "        intent_ood_label = json.loads(f.read())\n",
    "        self.intents_ood = list(intent_ood_label.keys())\n",
    "        return intent_ood_label\n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        return sentence.split()\n",
    "    \n",
    "    def tokenize_dataset(self, dataset):\n",
    "        token_dataset = []\n",
    "        for data in dataset:\n",
    "            token_dataset.append(self.tokenize(data))\n",
    "        return token_dataset\n",
    "\n",
    "    def make_ood_dataset(self, embed):\n",
    "        intent_dataset = pd.read_csv(self.intent_data_dir)\n",
    "        ood_dataset = pd.read_csv(self.ood_data_dir)#.sample(frac=1).reset_index(drop=True)\n",
    "        intent_dataset = pd.concat([intent_dataset,ood_dataset])\n",
    "        labels = []\n",
    "        for label in intent_dataset[\"label\"].to_list():\n",
    "            if(label == \"OOD\"):\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "            \n",
    "        intent_querys = self.tokenize_dataset(intent_dataset[\"question\"].tolist())\n",
    "        \n",
    "        dataset = list(zip(intent_querys, labels))\n",
    "        intent_train_dataset, intent_test_dataset = self.word2idx_dataset(dataset, embed)\n",
    "        return intent_train_dataset, intent_test_dataset\n",
    "    \n",
    "    \n",
    "    def word2idx_dataset(self, dataset ,embed, train_ratio = 0.8):\n",
    "        embed_dataset = []\n",
    "        question_list, label_list = [], []\n",
    "        flag = True\n",
    "        random.shuffle(dataset)\n",
    "        for query, label in dataset :\n",
    "            q_vec = embed.query2idx(query)\n",
    "            q_vec = self.prep.pad_idx_sequencing(q_vec)\n",
    "\n",
    "            question_list.append(torch.tensor([q_vec]))\n",
    "\n",
    "            label_list.append(torch.tensor([label]))\n",
    "\n",
    "        x = torch.cat(question_list)\n",
    "        y = torch.cat(label_list)\n",
    "\n",
    "        x_len = x.size()[0]\n",
    "        y_len = y.size()[0]\n",
    "        if(x_len == y_len):\n",
    "            train_size = int(x_len*train_ratio)\n",
    "            \n",
    "            train_x = x[:train_size]\n",
    "            train_y = y[:train_size]\n",
    "\n",
    "            test_x = x[train_size+1:]\n",
    "            test_y = y[train_size+1:]\n",
    "            \n",
    "            train_dataset = TensorDataset(train_x,train_y)\n",
    "            test_dataset = TensorDataset(test_x,test_y)\n",
    "            \n",
    "            return train_dataset, test_dataset\n",
    "            \n",
    "        else:\n",
    "            print(\"ERROR x!=y\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MakeDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저기 그림 화면 그릴 거야</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그림 틀어줄래</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저기 있잖아 그림 좀</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그림 그릴 거야</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그림 켜줄래</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12218</th>\n",
       "      <td>훔쳐보는 것 눈치 보임</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>훔쳐보는 것 눈치 보임</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>흑기사 해주는 짝남</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>OOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     question label\n",
       "0              저기 그림 화면 그릴 거야   OOD\n",
       "1                     그림 틀어줄래   OOD\n",
       "2                 저기 있잖아 그림 좀   OOD\n",
       "3                    그림 그릴 거야   OOD\n",
       "4                      그림 켜줄래   OOD\n",
       "...                       ...   ...\n",
       "12218            훔쳐보는 것 눈치 보임   OOD\n",
       "12219            훔쳐보는 것 눈치 보임   OOD\n",
       "12220              흑기사 해주는 짝남   OOD\n",
       "12221  힘든 연애 좋은 연애라는게 무슨 차이일까   OOD\n",
       "12222              힘들어서 결혼할까봐   OOD\n",
       "\n",
       "[12223 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(dataset.ood_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>야 먼지 알려주겠니</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아니 먼지 정보 알려주세요</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그 때 미세먼지 어떨까</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그 때 먼지 좋으려나</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미세먼지 어떨 것 같은데</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>구미 날씨 덥니</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>영암 우산 가져갈까</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>군포 비오냐</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>하남 덥냐</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>순천 우산 필요하니</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             question    label\n",
       "0          야 먼지 알려주겠니     dust\n",
       "1      아니 먼지 정보 알려주세요     dust\n",
       "2        그 때 미세먼지 어떨까     dust\n",
       "3         그 때 먼지 좋으려나     dust\n",
       "4       미세먼지 어떨 것 같은데     dust\n",
       "...               ...      ...\n",
       "19987        구미 날씨 덥니  weather\n",
       "19988      영암 우산 가져갈까  weather\n",
       "19989          군포 비오냐  weather\n",
       "19990           하남 덥냐  weather\n",
       "19991      순천 우산 필요하니  weather\n",
       "\n",
       "[19992 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(dataset.intent_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = MakeEmbed()\n",
    "embed.load_word2vec()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ood_train_dataset, ood_test_dataset = dataset.make_ood_dataset(embed)\n",
    "\n",
    "train_dataloader = DataLoader(ood_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(ood_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Unordered Composition Rivals Syntactic Methods for Text Classification\n",
    "## * Iyyer\n",
    "### tensorflow code(tf-hub로 제공) : https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "### keras code : https://github.com/candlewill/Vecamend-master2/blob/master/dan.py#L41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, w2v, dim, dropout, num_class = 2):\n",
    "        super(DAN, self).__init__()\n",
    "        #load pretrained embedding in embedding layer.\n",
    "        vocab_size = w2v.size()[0]\n",
    "        emb_dim = w2v.size()[1]\n",
    "        self.embed = nn.Embedding(vocab_size+2, emb_dim)\n",
    "        self.embed.weight[2:].data.copy_(w2v)\n",
    "        #self.embed.weight.requires_grad = False\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.bn1 = nn.BatchNorm1d(emb_dim)\n",
    "        self.fc1 = nn.Linear(emb_dim, dim)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.bn2 = nn.BatchNorm1d(dim)\n",
    "        self.fc2 = nn.Linear(dim, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb_x = self.embed(x)\n",
    "        #(128,20,300)\n",
    "        x = emb_x.mean(dim=1)\n",
    "        #(128,300)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        #(128,256)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn2(x)\n",
    "        logit = self.fc2(x)\n",
    "        #(128,2 )\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAN(\n",
       "  (embed): Embedding(1481, 300)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = embed.word2vec.wv.vectors\n",
    "weights = torch.FloatTensor(weights)\n",
    "\n",
    "model = DAN(weights, 256, 0.5, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 202/202 [00:03<00:00, 66.90batch/s, accuracy=95.454544, loss=0.137]\n",
      "Epoch 0: 100%|██████████| 51/51 [00:00<00:00, 254.90batch/s, accuracy=99.3, loss=0.0131] \n",
      "Epoch 1: 100%|██████████| 202/202 [00:02<00:00, 69.71batch/s, accuracy=100.0, loss=0.0139]    \n",
      "Epoch 1: 100%|██████████| 51/51 [00:00<00:00, 252.90batch/s, accuracy=99.4, loss=0.00244]\n",
      "Epoch 2: 100%|██████████| 202/202 [00:02<00:00, 69.50batch/s, accuracy=100.0, loss=0.00682]   \n",
      "Epoch 2: 100%|██████████| 51/51 [00:00<00:00, 261.41batch/s, accuracy=99.5, loss=0.00113]\n",
      "Epoch 3: 100%|██████████| 202/202 [00:03<00:00, 67.23batch/s, accuracy=95.454544, loss=0.0421]\n",
      "Epoch 3: 100%|██████████| 51/51 [00:00<00:00, 224.30batch/s, accuracy=99.6, loss=0.0217]  \n",
      "Epoch 4: 100%|██████████| 202/202 [00:03<00:00, 65.30batch/s, accuracy=100.0, loss=0.00108]   \n",
      "Epoch 4: 100%|██████████| 51/51 [00:00<00:00, 218.98batch/s, accuracy=99.6, loss=0.000712]\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "prev_acc = 0\n",
    "save_dir = \"./data/pretraining/1_ood_clsf_model//\"\n",
    "save_prefix = \"ood_clsf\"\n",
    "for i in range(epoch):\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    #for data in train_dataloader:\n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {i}\")\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            logit = model.forward(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            accuracy = 100.0 * corrects/x.size()[0]\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy= accuracy.numpy())\n",
    "            \n",
    "    model.eval()\n",
    "    steps = 0\n",
    "    accuarcy_list = []\n",
    "    #for data in test_dataloader:\n",
    "    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {i}\")\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "\n",
    "            logit = model.forward(x)\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            accuracy = 100.0 * corrects/x.size()[0]\n",
    "            accuarcy_list.append(accuracy.tolist())\n",
    "            \n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy= sum(accuarcy_list)/len(accuarcy_list))\n",
    "            \n",
    "    acc = sum(accuarcy_list)/len(accuarcy_list)\n",
    "    if(acc>prev_acc):\n",
    "        prev_acc = acc\n",
    "        save(model, save_dir, save_prefix+\"_\"+str(round(acc,3)), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAN(\n",
       "  (embed): Embedding(1481, 300)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./data/pretraining/save/1_ood_clsf_model/ood_clsf_99.724_steps_5.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발화 : 제주도\n",
      "ood\n",
      "CPU times: user 1.13 ms, sys: 898 µs, total: 2.03 ms\n",
      "Wall time: 1.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q = \"제주도\"\n",
    "\n",
    "x = dataset.prep.pad_idx_sequencing(embed.query2idx(dataset.tokenize(q)))\n",
    "\n",
    "x = torch.tensor(x)\n",
    "f = model(x.unsqueeze(0))\n",
    "\n",
    "y = torch.argmax(f).tolist()\n",
    "\n",
    "print(\"발화 : \" + q)\n",
    "if(not y):\n",
    "    print(\"ood\")\n",
    "else:\n",
    "    print(\"intent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발화 : 제주도 날씨\n",
      "intent\n",
      "CPU times: user 1.04 ms, sys: 837 µs, total: 1.88 ms\n",
      "Wall time: 990 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q = \"제주도 날씨\"\n",
    "\n",
    "x = dataset.prep.pad_idx_sequencing(embed.query2idx(dataset.tokenize(q)))\n",
    "\n",
    "x = torch.tensor(x)\n",
    "f = model(x.unsqueeze(0))\n",
    "\n",
    "y = torch.argmax(f).tolist()\n",
    "\n",
    "print(\"발화 : \" + q)\n",
    "if(not y):\n",
    "    print(\"ood\")\n",
    "else:\n",
    "    print(\"intent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

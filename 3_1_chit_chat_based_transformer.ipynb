{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "## 오픈 도메인 대화 테스크를 위한 데이터 처리\n",
    "### dataset : https://github.com/songys/Chatbot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('./data/dataset/ChatbotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence piece 로 vocab생성\n",
    "## SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing\n",
    "### * Taku Kudo, John Richardson, Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 기본적으로 vocab의 크기가 계산량에 영향을 주고 있습니다.\n",
    "그래서 적당한 크기의 vocab을 사용하게 됩니다. 문제는 여기서 많이 발생합니다.\n",
    "우리는 vocab을 만들때 미등록 단어가 발생하게 되고 실제로 입력으로 들어왔을때 UNK토큰으로 대체하게 됩니다.\n",
    "이 과정에서 정보의 손실이 발생하고 성능의 문제를 일으킬수 있습니다.\n",
    "그런 점을 보완하고자 sentencepiece를 tokenizer로 사용하려고 합니다.\n",
    "sentencepiece의 기본 아이디어는 단어(word)의 부분단어(subword)로 모든 단어를 표현하고자 하는게 아이디어입니다.\n",
    "이때 사용하는게 단어들의 빈도수를 사용하여 subword로 나눌지 말지를 판단하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"data/dataset/chit-chat_corpus.txt\"\n",
    "prefix = \"chatbot\"\n",
    "vocab_size = 16000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3박4일 정도 놀러가고 싶다\n",
      "['▁3', '박', '4', '일', '▁정도', '▁놀러가고', '▁싶다']\n",
      "[473, 15432, 15399, 14972, 982, 3503, 201]\n"
     ]
    }
   ],
   "source": [
    "vocab_file = \"chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "line = \"3박4일 정도 놀러가고 싶다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "\n",
    "\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import torch.nn.functional as F\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.model import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    '''\n",
    "    데이터의 최대 token길이가 10이지만\n",
    "    실제 환경에서는 얼마의 길이가 들어올지 몰라 적당한 길이 부여\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_len = 20):\n",
    "        self.max_len = max_len\n",
    "        self.PAD = 0\n",
    "    \n",
    "    def pad_idx_sequencing(self, q_vec):\n",
    "        q_len = len(q_vec)\n",
    "        diff_len = q_len - self.max_len\n",
    "        if(diff_len>0):\n",
    "            q_vec = q_vec[:self.max_len]\n",
    "            q_len = self.max_len\n",
    "        else:\n",
    "            pad_vac = [0] * abs(diff_len)\n",
    "            q_vec += pad_vac\n",
    "\n",
    "        return q_vec\n",
    "    \n",
    "    def make_batch(self):\n",
    "        pass\n",
    "\n",
    "class ChitChatDataset(data.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor, labels):\n",
    "        super(ChitChatDataset, self).__init__()\n",
    "\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "class MakeDataset:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.chitchat_data_dir = \"./data/dataset/ChatbotData.csv\"\n",
    "        \n",
    "        self.prep = Preprocessing()\n",
    "        vocab_file = \"chatbot.model\"\n",
    "        self.transformers_tokenizer = spm.SentencePieceProcessor()\n",
    "        self.transformers_tokenizer.load(vocab_file)\n",
    "    \n",
    "    def encode_dataset(self, dataset):\n",
    "        token_dataset = []\n",
    "        for data in dataset:\n",
    "            token_dataset.append( [2] + self.transformers_tokenizer.encode_as_ids(data) + [3])\n",
    "        return token_dataset\n",
    "\n",
    "    def make_chitchat_dataset(self, train_ratio = 0.8):\n",
    "        chitchat_dataset = pd.read_csv(self.chitchat_data_dir)\n",
    "        Qs = chitchat_dataset[\"Q\"].tolist()\n",
    "        As = chitchat_dataset[\"A\"].tolist()\n",
    "        label = chitchat_dataset[\"label\"].tolist()\n",
    "        \n",
    "        Qs = self.encode_dataset(Qs)\n",
    "        As = self.encode_dataset(As)\n",
    "        \n",
    "        self.prep.max_len = 40\n",
    "        x, y = [], []\n",
    "        for q, a in zip(Qs,As):\n",
    "            x.append(self.prep.pad_idx_sequencing(q))\n",
    "            y.append(self.prep.pad_idx_sequencing(a))\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        x_len = x.size()[0]\n",
    "        train_size = int(x_len*train_ratio)\n",
    "        \n",
    "        if(train_ratio == 1.0):\n",
    "            train_x = x[:train_size]\n",
    "            train_y = y[:train_size]\n",
    "            train_label = label[:train_size]\n",
    "            train_dataset = ChitChatDataset(train_x,train_y,train_label)\n",
    "            return train_dataset, None\n",
    "        else:\n",
    "            train_x = x[:train_size]\n",
    "            train_y = y[:train_size]\n",
    "            train_label = label[:train_size]\n",
    "\n",
    "            test_x = x[train_size+1:]\n",
    "            test_y = y[train_size+1:]\n",
    "            test_label = label[train_size+1:]\n",
    "\n",
    "            train_dataset = ChitChatDataset(train_x,train_y,train_label)\n",
    "            test_dataset = ChitChatDataset(test_x,test_y,test_label)\n",
    "\n",
    "            return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MakeDataset()\n",
    "\n",
    "train_dataset, test_dataset = dataset.make_chitchat_dataset(1.0)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Is All You Need\n",
    "## * Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
    "### tensorflow transformer chatbot code : https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "class Tformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim_model, num_heads, dff, num_layers, dropout_p=0.5):\n",
    "        super(Tformer, self).__init__()\n",
    "        self.transformer = Transformer(dim_model, num_heads, dim_feedforward=dff, num_encoder_layers=num_layers, num_decoder_layers=num_layers,dropout=dropout_p)\n",
    "        self.pos_encoder = PositionalEncoding(dim_model, dropout_p)\n",
    "        self.encoder = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(dim_model, dropout_p)\n",
    "        self.encoder_d = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        self.dim_model = dim_model\n",
    "        self.num_tokens = num_tokens\n",
    "\n",
    "        self.linear = nn.Linear(dim_model, num_tokens)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.dim_model)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.dim_model)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tformer(\n",
    "     num_tokens=vocab_size+7, dim_model=256, num_heads=8, dff=512, num_layers=2, dropout_p=0.1\n",
    " ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.281: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]\n",
      "1.356:   1%|          | 1/93 [00:00<00:11,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1 | loss: 2.3234646704889115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.911: 100%|██████████| 93/93 [00:11<00:00,  8.11it/s]\n",
      "1.025:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2 | loss: 1.1157909106182795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.004: 100%|██████████| 93/93 [00:11<00:00,  8.30it/s]\n",
      "0.916:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3 | loss: 0.9776405416509156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.880: 100%|██████████| 93/93 [00:11<00:00,  8.27it/s]\n",
      "0.935:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4 | loss: 0.9354389970020581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.837: 100%|██████████| 93/93 [00:11<00:00,  8.29it/s]\n",
      "0.884:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5 | loss: 0.9105411652595766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.967: 100%|██████████| 93/93 [00:11<00:00,  8.28it/s]\n",
      "0.831:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6 | loss: 0.8927132391160534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.932: 100%|██████████| 93/93 [00:11<00:00,  8.28it/s]\n",
      "0.826:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7 | loss: 0.876556888703377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.970: 100%|██████████| 93/93 [00:11<00:00,  8.27it/s]\n",
      "0.832:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8 | loss: 0.8623861497448336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.807: 100%|██████████| 93/93 [00:11<00:00,  8.26it/s]\n",
      "0.868:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9 | loss: 0.848002197921917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.884: 100%|██████████| 93/93 [00:11<00:00,  8.22it/s]\n",
      "0.801:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10 | loss: 0.8365371868174564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.815: 100%|██████████| 93/93 [00:11<00:00,  8.15it/s]\n",
      "0.783:   1%|          | 1/93 [00:00<00:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11 | loss: 0.8242870864047799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.709: 100%|██████████| 93/93 [00:11<00:00,  8.18it/s]\n",
      "0.754:   1%|          | 1/93 [00:00<00:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 12 | loss: 0.8122200094243531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.828: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.745:   1%|          | 1/93 [00:00<00:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 13 | loss: 0.8009871616158434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.734: 100%|██████████| 93/93 [00:11<00:00,  8.09it/s]\n",
      "0.789:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 14 | loss: 0.7890248452463458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.727: 100%|██████████| 93/93 [00:11<00:00,  8.13it/s]\n",
      "0.788:   1%|          | 1/93 [00:00<00:11,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 15 | loss: 0.7768357799899194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.869: 100%|██████████| 93/93 [00:11<00:00,  8.09it/s]\n",
      "0.744:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 16 | loss: 0.766856942125546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.680: 100%|██████████| 93/93 [00:11<00:00,  8.21it/s]\n",
      "0.746:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 17 | loss: 0.7539601479807208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.867: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]\n",
      "0.726:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 18 | loss: 0.743398933000462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.809: 100%|██████████| 93/93 [00:11<00:00,  8.10it/s]\n",
      "0.761:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 19 | loss: 0.7318354780955981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.716: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.657:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 20 | loss: 0.7197605256111391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.796: 100%|██████████| 93/93 [00:11<00:00,  8.05it/s]\n",
      "0.713:   1%|          | 1/93 [00:00<00:11,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 21 | loss: 0.7089048816311744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.640: 100%|██████████| 93/93 [00:11<00:00,  8.01it/s]\n",
      "0.665:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 22 | loss: 0.6971188617008989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.611: 100%|██████████| 93/93 [00:11<00:00,  7.97it/s]\n",
      "0.720:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 23 | loss: 0.6860599722913516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.663: 100%|██████████| 93/93 [00:11<00:00,  8.03it/s]\n",
      "0.656:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 24 | loss: 0.6752831243699596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.607: 100%|██████████| 93/93 [00:11<00:00,  8.02it/s]\n",
      "0.620:   1%|          | 1/93 [00:00<00:11,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 25 | loss: 0.6642456464870001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.601: 100%|██████████| 93/93 [00:11<00:00,  8.03it/s]\n",
      "0.629:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 26 | loss: 0.653590335640856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.577: 100%|██████████| 93/93 [00:11<00:00,  8.01it/s]\n",
      "0.583:   1%|          | 1/93 [00:00<00:11,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 27 | loss: 0.6430304742628529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.703: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.652:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 28 | loss: 0.6326892401582451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.637: 100%|██████████| 93/93 [00:11<00:00,  8.15it/s]\n",
      "0.581:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 29 | loss: 0.6222906625399025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.590: 100%|██████████| 93/93 [00:11<00:00,  8.16it/s]\n",
      "0.612:   1%|          | 1/93 [00:00<00:11,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 30 | loss: 0.6117681277695523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.673: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.597:   1%|          | 1/93 [00:00<00:11,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 31 | loss: 0.602153080765919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.613: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]\n",
      "0.554:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 32 | loss: 0.5921946699901294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.547: 100%|██████████| 93/93 [00:11<00:00,  8.21it/s]\n",
      "0.630:   1%|          | 1/93 [00:00<00:11,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 33 | loss: 0.5819651285807291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.558: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]\n",
      "0.572:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 34 | loss: 0.5722229250015751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.612: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.557:   1%|          | 1/93 [00:00<00:11,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 35 | loss: 0.563101327547463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.564: 100%|██████████| 93/93 [00:11<00:00,  8.02it/s]\n",
      "0.558:   1%|          | 1/93 [00:00<00:11,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 36 | loss: 0.5528981608729209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.542: 100%|██████████| 93/93 [00:11<00:00,  8.15it/s]\n",
      "0.547:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 37 | loss: 0.5437782451670657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.498: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.527:   1%|          | 1/93 [00:00<00:11,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 38 | loss: 0.5337357059601815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.461: 100%|██████████| 93/93 [00:11<00:00,  8.11it/s]\n",
      "0.536:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 39 | loss: 0.5236127709829679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.439: 100%|██████████| 93/93 [00:11<00:00,  8.10it/s]\n",
      "0.557:   1%|          | 1/93 [00:00<00:12,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 40 | loss: 0.5144784168530536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.535: 100%|██████████| 93/93 [00:11<00:00,  8.20it/s]\n",
      "0.499:   1%|          | 1/93 [00:00<00:11,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 41 | loss: 0.5061038437710014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.543: 100%|██████████| 93/93 [00:11<00:00,  8.20it/s]\n",
      "0.486:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 42 | loss: 0.4971876246954805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.535: 100%|██████████| 93/93 [00:11<00:00,  8.13it/s]\n",
      "0.474:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 43 | loss: 0.48777098296790994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.442: 100%|██████████| 93/93 [00:11<00:00,  8.14it/s]\n",
      "0.472:   1%|          | 1/93 [00:00<00:12,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 44 | loss: 0.47800023068663894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.538: 100%|██████████| 93/93 [00:11<00:00,  8.13it/s]\n",
      "0.474:   1%|          | 1/93 [00:00<00:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 45 | loss: 0.4703238292406964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.363: 100%|██████████| 93/93 [00:11<00:00,  8.18it/s]\n",
      "0.444:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 46 | loss: 0.45990626017252606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.474: 100%|██████████| 93/93 [00:11<00:00,  8.18it/s]\n",
      "0.424:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 47 | loss: 0.45153775779149863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.534: 100%|██████████| 93/93 [00:11<00:00,  8.04it/s]\n",
      "0.432:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 48 | loss: 0.4442020539314516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.464: 100%|██████████| 93/93 [00:11<00:00,  8.17it/s]\n",
      "0.391:   1%|          | 1/93 [00:00<00:11,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 49 | loss: 0.43474070231119794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.430: 100%|██████████| 93/93 [00:11<00:00,  8.14it/s]\n",
      "0.396:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 50 | loss: 0.4257750562442246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.447: 100%|██████████| 93/93 [00:11<00:00,  8.18it/s]\n",
      "0.417:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 51 | loss: 0.41748797508978075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.401: 100%|██████████| 93/93 [00:11<00:00,  7.94it/s]\n",
      "0.401:   1%|          | 1/93 [00:00<00:11,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 52 | loss: 0.4087578558152722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.411: 100%|██████████| 93/93 [00:11<00:00,  8.22it/s]\n",
      "0.387:   1%|          | 1/93 [00:00<00:12,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 53 | loss: 0.40111566358996975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.353: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]\n",
      "0.380:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 54 | loss: 0.3915512331070439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.381: 100%|██████████| 93/93 [00:11<00:00,  8.19it/s]\n",
      "0.375:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 55 | loss: 0.3840788974556872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.436: 100%|██████████| 93/93 [00:11<00:00,  8.18it/s]\n",
      "0.346:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 56 | loss: 0.3764425298219086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.339: 100%|██████████| 93/93 [00:11<00:00,  8.11it/s]\n",
      "0.384:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 57 | loss: 0.36801959622290825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.325: 100%|██████████| 93/93 [00:11<00:00,  8.15it/s]\n",
      "0.346:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 58 | loss: 0.3607729019657258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.380: 100%|██████████| 93/93 [00:11<00:00,  8.13it/s]\n",
      "0.325:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 59 | loss: 0.35287639658938175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.380: 100%|██████████| 93/93 [00:11<00:00,  8.22it/s]\n",
      "0.357:   1%|          | 1/93 [00:00<00:11,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 60 | loss: 0.3451576232910156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.372: 100%|██████████| 93/93 [00:11<00:00,  8.08it/s]\n",
      "0.328:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 61 | loss: 0.3381924988121115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.299: 100%|██████████| 93/93 [00:11<00:00,  8.24it/s]\n",
      "0.297:   1%|          | 1/93 [00:00<00:11,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 62 | loss: 0.3298845598774572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.312: 100%|██████████| 93/93 [00:11<00:00,  8.10it/s]\n",
      "0.308:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 63 | loss: 0.322441654820596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.272: 100%|██████████| 93/93 [00:11<00:00,  8.13it/s]\n",
      "0.298:   1%|          | 1/93 [00:00<00:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 64 | loss: 0.3148705267137097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.367: 100%|██████████| 93/93 [00:11<00:00,  8.16it/s]\n",
      "0.281:   1%|          | 1/93 [00:00<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 65 | loss: 0.3082339379095262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.321: 100%|██████████| 93/93 [00:11<00:00,  8.04it/s]\n",
      "0.301:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 66 | loss: 0.3013299921507476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.317: 100%|██████████| 93/93 [00:11<00:00,  8.24it/s]\n",
      "0.295:   1%|          | 1/93 [00:00<00:11,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 67 | loss: 0.29473634945449007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.252: 100%|██████████| 93/93 [00:11<00:00,  8.10it/s]\n",
      "0.274:   1%|          | 1/93 [00:00<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 68 | loss: 0.28686312193511637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.267: 100%|██████████| 93/93 [00:11<00:00,  8.19it/s]\n",
      "0.259:   1%|          | 1/93 [00:00<00:11,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 69 | loss: 0.2803343906197497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.278: 100%|██████████| 93/93 [00:11<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 70 | loss: 0.2735347952893985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 70\n",
    "save_dir = \"./data/pretraining/4_chitchat_transformer_model/\"\n",
    "save_prefix = \"chitchat_transformer\"\n",
    "prev_loss_all = float(\"inf\")\n",
    "train_steps = 0\n",
    "test_steps = 0\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(train_dataloader)\n",
    "    for (inputs, y, _) in progress:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        dec_inputs = y[:,:-1]\n",
    "        outputs = y[:,1:]\n",
    "        \n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).cuda()\n",
    "        src_padding_mask = gen_attention_mask(inputs).cuda()\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).cuda()\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).cuda()\n",
    "\n",
    "        result = model(inputs.long().cuda(), dec_inputs.long().cuda(), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.long().cuda())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "\n",
    "        train_steps += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    \n",
    "    print(\"train epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(train_dataloader))\n",
    "\n",
    "#     model.eval()\n",
    "#     test_batchloss = 0.0\n",
    "#     progress_test = tqdm(test_dataloader)\n",
    "#     for (inputs, y, _) in progress_test:\n",
    "\n",
    "#         dec_inputs = y[:,:-1]\n",
    "#         outputs = y[:,1:]\n",
    "        \n",
    "#         src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).cuda()\n",
    "#         src_padding_mask = gen_attention_mask(inputs).cuda()\n",
    "#         tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).cuda()\n",
    "#         tgt_padding_mask = gen_attention_mask(dec_inputs).cuda()\n",
    "\n",
    "#         result = model(inputs.long().cuda(), dec_inputs.long().cuda(), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    " \n",
    "#         loss = criterion(result.permute(1,2,0), outputs.long().cuda())\n",
    "#         progress_test.set_description(\"{:0.3f}\".format(loss.cpu().item()))\n",
    "\n",
    "#         test_steps += 1\n",
    "#         test_batchloss += loss.cpu().item()\n",
    "#     loss_all = test_batchloss/len(test_dataloader)\n",
    "#     print(\"test epoch:\",i+1,\"|\",\"loss:\",loss_all)\n",
    "#     model.train()\n",
    "#     if(loss_all<prev_loss_all):\n",
    "#         prev_loss_all = loss_all\n",
    "#         save(model, save_dir, save_prefix + \"_\" + str(round(loss_all,6)), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2783, device='cuda:0', grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, save_dir, save_prefix + \"_\" + str(round(loss.cpu().item(),6)), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([[2] + vocab.encode_as_ids(sentence) + [3]]).cuda()\n",
    "    output = torch.tensor([[2]]).cuda()\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).cuda()\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).cuda()\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).cuda()\n",
    "        tgt_padding_mask = gen_attention_mask(output).cuda()\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(3)):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.cuda()], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Embedding(16007, 256)\n",
       "  (pos_encoder_d): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_d): Embedding(16007, 256)\n",
       "  (linear): Linear(in_features=256, out_features=16007, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./data/pretraining/save/4_chitchat_transformer_model/chitchat_transformer_1.215381_steps_81.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 뭘 해야 할까?\n",
      "Output: 정말 힘드신가봐요. 본인의 의사를 확실히 밝혀보세요 대한 두려움을 가지고 손해배상을 청구하세요.\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"난 뭘 해야 할까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 힘들다\n",
      "Output: 이제 회사와 자신에 대해서 더 공부해서 자신감을 가지세요.\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"힘들다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 혼자인게 좋아\n",
      "Output: 스트레스 받으시는 말고 적극적으로 장점을 찾아서 인정하고 호의를 보여보세요.\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"난 혼자인게 좋아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 결혼해줘\n",
      "Output: 더 힘들 겠지만 못해요하는 어제 더 면밀히 더 면밀히 더 면밀히 걸리겠지만 해낼 수도 있어요. 작은하는 어제 더 힘들 겠지만요하는 어제 더 힘들 겠지만요하는 어제 더 힘들 겠지만요군요\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"결혼해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
